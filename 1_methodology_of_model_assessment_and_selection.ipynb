{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology of model assessment and selection\n",
    "\n",
    "To compare two or more models i will use auc as a metric. To estimate this quantity with confidence i use k-fold cross validation: \n",
    "\n",
    "The data set is split with a ratio of 80 to 20 into a training and a test set. The test will be untouched until the very and of the analysis. The training set then is used for the crossvalidation loop. \n",
    "\n",
    "I implemented this with the help of the *caret* package in the *helpers* script. Note that the *helpers* script loads *tidyverse* and *caret* implicit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tidyverse' was built under R version 3.6.1\"Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n",
      "-- Attaching packages --------------------------------------- tidyverse 1.2.1 --\n",
      "v ggplot2 3.1.1       v purrr   0.3.2  \n",
      "v tibble  2.1.1       v dplyr   0.8.0.1\n",
      "v tidyr   0.8.3       v stringr 1.4.0  \n",
      "v readr   1.3.1       v forcats 0.4.0  \n",
      "-- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "x dplyr::filter() masks stats::filter()\n",
      "x dplyr::lag()    masks stats::lag()\n",
      "Warning message:\n",
      "\"package 'caret' was built under R version 3.6.1\"Loading required package: lattice\n",
      "\n",
      "Attaching package: 'caret'\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    lift\n",
      "\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  age = col_double(),\n",
      "  sex = col_double(),\n",
      "  cp = col_double(),\n",
      "  trestbps = col_double(),\n",
      "  chol = col_double(),\n",
      "  fbs = col_double(),\n",
      "  restecg = col_double(),\n",
      "  thalach = col_double(),\n",
      "  exang = col_double(),\n",
      "  oldpeak = col_double(),\n",
      "  slope = col_double(),\n",
      "  ca = col_double(),\n",
      "  thal = col_double(),\n",
      "  target = col_double()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 243\n",
      "Variables: 14\n",
      "$ age      <dbl> 63, 37, 41, 56, 57, 56, 44, 52, 57, 54, 48, 49, 64, 58, 50...\n",
      "$ thalach  <dbl> 150, 187, 172, 178, 163, 153, 173, 162, 174, 160, 139, 171...\n",
      "$ trestbps <dbl> 145, 130, 130, 120, 120, 140, 120, 172, 150, 140, 130, 130...\n",
      "$ oldpeak  <dbl> 2.3, 3.5, 1.4, 0.8, 0.6, 1.3, 0.0, 0.5, 1.6, 1.2, 0.2, 0.6...\n",
      "$ ca       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...\n",
      "$ chol     <dbl> 233, 250, 204, 236, 354, 294, 263, 199, 168, 239, 275, 266...\n",
      "$ restecg  <fct> normal, ST-T_abnormalty, normal, ST-T_abnormalty, ST-T_abn...\n",
      "$ fbs      <fct> yes, no, no, no, no, no, no, yes, no, no, no, no, no, yes,...\n",
      "$ sex      <fct> Male, Male, Female, Male, Female, Female, Male, Male, Male...\n",
      "$ exang    <fct> no, no, no, no, yes, no, no, no, no, no, no, no, yes, no, ...\n",
      "$ cp       <fct> asymptomatic, non-anginal_pain, atypical_angina, atypical_...\n",
      "$ slope    <fct> upsloping, upsloping, downsloping, downsloping, downslopin...\n",
      "$ target   <fct> disease, disease, disease, disease, disease, disease, dise...\n",
      "$ thal     <fct> fixed_defect, reversable_defect, reversable_defect, revers...\n"
     ]
    }
   ],
   "source": [
    "source(\"helpers.r\")\n",
    "df <- get_training_df()\n",
    "glimpse(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-fold cross validation is now set up with $k = 10$. A tibble that stores the results is also prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'MLmetrics' was built under R version 3.6.1\"\n",
      "Attaching package: 'MLmetrics'\n",
      "\n",
      "The following objects are masked from 'package:caret':\n",
      "\n",
      "    MAE, RMSE\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    Recall\n",
      "\n",
      "\n",
      "Attaching package: 'magrittr'\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    set_names\n",
      "\n",
      "The following object is masked from 'package:tidyr':\n",
      "\n",
      "    extract\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>model</th><th scope=col>mean</th><th scope=col>median</th><th scope=col>sd</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>logistic regression</td><td>0.8936314          </td><td>0.8921079          </td><td>0.06699914         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " model & mean & median & sd\\\\\n",
       "\\hline\n",
       "\t logistic regression & 0.8936314           & 0.8921079           & 0.06699914         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| model | mean | median | sd |\n",
       "|---|---|---|---|\n",
       "| logistic regression | 0.8936314           | 0.8921079           | 0.06699914          |\n",
       "\n"
      ],
      "text/plain": [
       "  model               mean      median    sd        \n",
       "1 logistic regression 0.8936314 0.8921079 0.06699914"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(MLmetrics)\n",
    "library(magrittr)\n",
    "\n",
    "set.seed(25)\n",
    "number_of_folds <- 10\n",
    "folds <- createFolds(df$target, k = number_of_folds)\n",
    "model_result <- tibble(model = vector(\"character\"),\n",
    "                       auc = vector(\"numeric\"))\n",
    "\n",
    "for(fold_index in c(1:number_of_folds)){\n",
    "    training <- df[-folds[[fold_index]],]\n",
    "    test <- df[folds[[fold_index]],]\n",
    "    \n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "    \n",
    "    fit <- glm(target ~ ., data=training, family =binomial(link = \"logit\"))\n",
    "    y_probabilities <- unname(predict(fit, test,  type=\"response\"))\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    \n",
    "    model_result %<>%\n",
    "      add_row(model = \"logistic regression\", auc = auc)\n",
    " \n",
    "  }\n",
    "\n",
    "model_result %>%\n",
    "    group_by(model) %>%\n",
    "    summarize(mean = mean(auc),\n",
    "              median = median(auc),\n",
    "              sd = sd(auc))\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that i already created the tibble that is used to store the result with a column for different models. Now let's extend the cross validation loop to compare two different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>model</th><th scope=col>mean</th><th scope=col>median</th><th scope=col>sd</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>decision tree      </td><td>0.8191850          </td><td>0.8198052          </td><td>0.06599059         </td></tr>\n",
       "\t<tr><td>logistic regression</td><td>0.8936314          </td><td>0.8921079          </td><td>0.06699914         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " model & mean & median & sd\\\\\n",
       "\\hline\n",
       "\t decision tree       & 0.8191850           & 0.8198052           & 0.06599059         \\\\\n",
       "\t logistic regression & 0.8936314           & 0.8921079           & 0.06699914         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| model | mean | median | sd |\n",
       "|---|---|---|---|\n",
       "| decision tree       | 0.8191850           | 0.8198052           | 0.06599059          |\n",
       "| logistic regression | 0.8936314           | 0.8921079           | 0.06699914          |\n",
       "\n"
      ],
      "text/plain": [
       "  model               mean      median    sd        \n",
       "1 decision tree       0.8191850 0.8198052 0.06599059\n",
       "2 logistic regression 0.8936314 0.8921079 0.06699914"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(rpart)\n",
    "model_result <- tibble(model = vector(\"character\"),\n",
    "                       auc = vector(\"numeric\"))\n",
    "models <- c(\"logistic regression\", \"decision tree\")\n",
    "\n",
    "for(model in models){\n",
    "    for(fold_index in c(1:number_of_folds)){\n",
    "        training <- df[-folds[[fold_index]],]\n",
    "        test <- df[folds[[fold_index]],]\n",
    "\n",
    "        y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "        if (model == \"logistic regression\") {\n",
    "          fit <- glm(target ~., data=training, family =binomial(link = \"logit\"))\n",
    "          y_probabilities <- unname(predict(fit, test,  type=\"response\"))\n",
    "        }\n",
    "        if (model == \"decision tree\"){\n",
    "          fit <- rpart(target ~., data=training, method = \"class\")\n",
    "          y_probabilities <- unname(predict(fit, test)[,2])\n",
    "        }\n",
    "\n",
    "        auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "\n",
    "        model_result %<>%\n",
    "          add_row(model = model, auc = auc)\n",
    "\n",
    "      }\n",
    "}\n",
    "\n",
    "model_result %>%\n",
    "    group_by(model) %>%\n",
    "    summarize(mean = mean(auc),\n",
    "              median = median(auc),\n",
    "              sd = sd(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visual inspect, that the logistic regression performs probably better than the decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAzMzNNTU1oaGh8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\nSWpgSFIDQ5IaGJLUwJCkBv8P9KbUFoFEBWYAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_result %>%\n",
    "    mutate(model = factor(model, levels = models)) %>%\n",
    "    ggplot(aes(x = model, y = auc))+\n",
    "    geom_boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To really compare the models a t-test is probably useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tPaired t-test\n",
       "\n",
       "data:  auc_log_reg and auc_tree\n",
       "t = 4.1435, df = 9, p-value = 0.002508\n",
       "alternative hypothesis: true difference in means is not equal to 0\n",
       "95 percent confidence interval:\n",
       " 0.0338026 0.1150902\n",
       "sample estimates:\n",
       "mean of the differences \n",
       "             0.07444639 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc_log_reg <- model_result %>%\n",
    "  filter(model == \"logistic regression\")\n",
    "auc_log_reg <- auc_log_reg[, \"auc\", drop = TRUE]\n",
    "auc_tree <- model_result %>%\n",
    "  filter(model == \"decision tree\")\n",
    "auc_tree <- auc_tree[, \"auc\",  drop = TRUE]\n",
    "\n",
    "t.test(auc_log_reg, auc_tree, paired = TRUE, alternative = \"two.sided\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provided that the assumption of the test setting were fulfilled, the difference of the means is significant and hence the logistic regression has a better performance. \n",
    "\n",
    "In the paper *\"Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithm\"* from Thomas Dietterich, 1997 the high probability of a Type I error of this test is shown. This is because the test and training sets are not really indepentently drawn. \n",
    "\n",
    "The loop for the crossvalidation builds the baseline for my analysis and is will be extended through the process. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
