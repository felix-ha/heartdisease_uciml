{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Models\n",
    "\n",
    "Define models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tidyverse' was built under R version 3.6.1\"Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n",
      "-- Attaching packages --------------------------------------- tidyverse 1.2.1 --\n",
      "v ggplot2 3.1.1       v purrr   0.3.2  \n",
      "v tibble  2.1.1       v dplyr   0.8.0.1\n",
      "v tidyr   0.8.3       v stringr 1.4.0  \n",
      "v readr   1.3.1       v forcats 0.4.0  \n",
      "-- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "x dplyr::filter() masks stats::filter()\n",
      "x dplyr::lag()    masks stats::lag()\n",
      "Warning message:\n",
      "\"package 'caret' was built under R version 3.6.1\"Loading required package: lattice\n",
      "\n",
      "Attaching package: 'caret'\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    lift\n",
      "\n",
      "Warning message:\n",
      "\"package 'MLmetrics' was built under R version 3.6.1\"\n",
      "Attaching package: 'MLmetrics'\n",
      "\n",
      "The following objects are masked from 'package:caret':\n",
      "\n",
      "    MAE, RMSE\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    Recall\n",
      "\n",
      "\n",
      "Attaching package: 'magrittr'\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    set_names\n",
      "\n",
      "The following object is masked from 'package:tidyr':\n",
      "\n",
      "    extract\n",
      "\n",
      "Warning message:\n",
      "\"package 'glmnet' was built under R version 3.6.1\"Loading required package: Matrix\n",
      "\n",
      "Attaching package: 'Matrix'\n",
      "\n",
      "The following object is masked from 'package:tidyr':\n",
      "\n",
      "    expand\n",
      "\n",
      "Loaded glmnet 3.0\n",
      "\n",
      "Warning message:\n",
      "\"package 'rpart' was built under R version 3.6.1\"Warning message:\n",
      "\"package 'ipred' was built under R version 3.6.1\"Warning message:\n",
      "\"package 'randomForest' was built under R version 3.6.1\"randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: 'randomForest'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    margin\n",
      "\n",
      "Warning message:\n",
      "\"package 'fastAdaboost' was built under R version 3.6.1\"Warning message:\n",
      "\"package 'gbm' was built under R version 3.6.2\"Loaded gbm 2.1.5\n",
      "Warning message:\n",
      "\"package 'xgboost' was built under R version 3.6.2\"\n",
      "Attaching package: 'xgboost'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    slice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source(\"helpers.r\")\n",
    "library(magrittr)\n",
    "library(glmnet)\n",
    "library(rpart)\n",
    "library(ipred)\n",
    "library(randomForest)\n",
    "library(fastAdaboost)\n",
    "library(gbm)\n",
    "library(xgboost)\n",
    "\n",
    "learner_A <- function(training, test) {\n",
    "  name <- \"lg full\"\n",
    "  \n",
    "  fit <- glm(target ~ ., data=training, family =binomial(link = \"logit\"))\n",
    "  y_probabilities <- predict(fit, test,  type=\"response\")\n",
    "  y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "  \n",
    "  auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "  return(list(name = name, auc = auc))\n",
    "}\n",
    "\n",
    "\n",
    "learner_B <- function(training, test) {\n",
    "  name <- \"lg forwad selection\"\n",
    "  \n",
    "  fit <- glm(target ~ thal + ca + cp + slope + oldpeak + sex + trestbps, data=training, family =binomial(link = \"logit\"))\n",
    "  y_probabilities <- predict(fit, test,  type=\"response\")\n",
    "  y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "  \n",
    "  auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "  return(list(name = name, auc = auc))\n",
    "}\n",
    "\n",
    "learner_C <- function(training, test) {   \n",
    "  name <- \"glm 5 variables LASSO\"\n",
    "    \n",
    "  fit <- glm(target ~ thalach + oldpeak + ca + cp + thal, data=training, family = binomial(link = \"logit\"))\n",
    "  y_probabilities <- predict(fit, test,  type=\"response\")\n",
    "  y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "    \n",
    "  auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "  return(list(name = name, auc = auc))\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "learner_D <- function(training, test) {   \n",
    "    name <- \"glmnet\"\n",
    "    \n",
    "    model <- model.matrix(target ~ ., training)[,-1]\n",
    "    y <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "    fit <- glmnet(model, y, alpha = 0, family = \"binomial\", lambda = 0.5, standardize = TRUE)\n",
    "\n",
    "    x_test  <- model.matrix(target ~ ., test)[,-1]\n",
    "    y_probabilities <- predict(fit, x_test,  type=\"response\")\n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "}\n",
    "\n",
    "learner_E  <- function(training, test){\n",
    "    \n",
    "        name <- \"rpart\"\n",
    "    \n",
    "    model <- model.matrix(target ~ ., training)[,-1]\n",
    "    y <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "   \n",
    "        \n",
    "    fit <- rpart(target ~., data=df, method = \"class\",\n",
    "                 control = rpart.control(maxdepth = 5, minbucket = 10, minsplit = 10), cp = 0.1)\n",
    "\n",
    "    y_probabilities <- predict(fit, test)[,2]\n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "\n",
    "}\n",
    "\n",
    "learner_F <- function(training, test){\n",
    "    \n",
    "        name <- \"bagging\"\n",
    "    \n",
    "    model <- model.matrix(target ~ ., training)[,-1]\n",
    "    y <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "   \n",
    "        \n",
    "  fit <- bagging(target ~ ., training,\n",
    "                 nbagg = 100,\n",
    "                 coob = FALSE,\n",
    "                 control = rpart.control(maxdepth = 20, minbucket = 7,\n",
    "                                         minsplit = 10), cp = 0.1)\n",
    "  \n",
    "  y_probabilities <- predict(fit, test, type = \"prob\")[,2]\n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "learner_G <- function(training, test){\n",
    "    \n",
    "        name <- \"randomforest\"\n",
    "    \n",
    "    model <- model.matrix(target ~ ., training)[,-1]\n",
    "    y <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "   \n",
    "        \n",
    "     fit <- randomForest(target ~ ., training,  ntree = 100, mtry = 2,\n",
    "                        nodesize = 10, maxnodes = 4)\n",
    "    # using ratio of poisitive labels as probability\n",
    "    y_probabilities <- predict(fit, test, type = \"vote\")[,2]\n",
    "    \n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "\n",
    "}\n",
    "\n",
    "learner_H <- function(training, test){\n",
    "    \n",
    "        name <- \"adaboost\"\n",
    "    \n",
    "    model <- model.matrix(target ~ ., training)[,-1]\n",
    "    y <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "   \n",
    "    training <- as.data.frame(training) \n",
    "   fit <- adaboost(target ~ ., training, nIter = 100)\n",
    "    y_probabilities <- predict(fit, test)$prob[,2]\n",
    "    \n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "\n",
    "}\n",
    "\n",
    "learner_I <- function(training, test){\n",
    "    \n",
    "    name <- \"gbm\"\n",
    "\n",
    "    y <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    training$target <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    fit <- gbm(target ~ ., data = training, distribution = \"bernoulli\",\n",
    "         n.trees = 10, interaction.depth = 10,\n",
    "         n.minobsinnode = 5)\n",
    "\n",
    "\n",
    "\n",
    "    y_probabilities <- predict(fit, test, type = \"response\", n.trees = 10)\n",
    "   \n",
    "    \n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learner_J <- function(training, test) {\n",
    "    name <- \"xgboost\"\n",
    "\n",
    "    df_matrix <- sparse.model.matrix(target ~ .-1, data = training)\n",
    "    dtrain <- xgb.DMatrix(df_matrix, label = ifelse(training$target == \"no_disease\", 0, 1))\n",
    "\n",
    "    param <- list(max_depth = 2, eta = 0.1, verbose = 0, nthread = 2,\n",
    "          objective = \"binary:logistic\")\n",
    "\n",
    "    fit <- xgb.train(param, dtrain, nrounds = 50)\n",
    "\n",
    "    df_matrix <- sparse.model.matrix(target ~ .-1, data = test)\n",
    "    dtest <- xgb.DMatrix(df_matrix, label = ifelse(test$target == \"no_disease\", 0, 1))\n",
    "    \n",
    "    y_probabilities <- predict(fit, dtest)\n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>model</th><th scope=col>MeanAUC</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>lg forwad selection  </td><td>0.9227572            </td></tr>\n",
       "\t<tr><td>glmnet               </td><td>0.9196304            </td></tr>\n",
       "\t<tr><td>randomforest         </td><td>0.9129620            </td></tr>\n",
       "\t<tr><td>bagging              </td><td>0.9100699            </td></tr>\n",
       "\t<tr><td>glm 5 variables LASSO</td><td>0.9054346            </td></tr>\n",
       "\t<tr><td>lg full              </td><td>0.9035265            </td></tr>\n",
       "\t<tr><td>gbm                  </td><td>0.9029670            </td></tr>\n",
       "\t<tr><td>rpart                </td><td>0.8997053            </td></tr>\n",
       "\t<tr><td>xgboost              </td><td>0.8990210            </td></tr>\n",
       "\t<tr><td>adaboost             </td><td>0.8705095            </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " model & MeanAUC\\\\\n",
       "\\hline\n",
       "\t lg forwad selection   & 0.9227572            \\\\\n",
       "\t glmnet                & 0.9196304            \\\\\n",
       "\t randomforest          & 0.9129620            \\\\\n",
       "\t bagging               & 0.9100699            \\\\\n",
       "\t glm 5 variables LASSO & 0.9054346            \\\\\n",
       "\t lg full               & 0.9035265            \\\\\n",
       "\t gbm                   & 0.9029670            \\\\\n",
       "\t rpart                 & 0.8997053            \\\\\n",
       "\t xgboost               & 0.8990210            \\\\\n",
       "\t adaboost              & 0.8705095            \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| model | MeanAUC |\n",
       "|---|---|\n",
       "| lg forwad selection   | 0.9227572             |\n",
       "| glmnet                | 0.9196304             |\n",
       "| randomforest          | 0.9129620             |\n",
       "| bagging               | 0.9100699             |\n",
       "| glm 5 variables LASSO | 0.9054346             |\n",
       "| lg full               | 0.9035265             |\n",
       "| gbm                   | 0.9029670             |\n",
       "| rpart                 | 0.8997053             |\n",
       "| xgboost               | 0.8990210             |\n",
       "| adaboost              | 0.8705095             |\n",
       "\n"
      ],
      "text/plain": [
       "   model                 MeanAUC  \n",
       "1  lg forwad selection   0.9227572\n",
       "2  glmnet                0.9196304\n",
       "3  randomforest          0.9129620\n",
       "4  bagging               0.9100699\n",
       "5  glm 5 variables LASSO 0.9054346\n",
       "6  lg full               0.9035265\n",
       "7  gbm                   0.9029670\n",
       "8  rpart                 0.8997053\n",
       "9  xgboost               0.8990210\n",
       "10 adaboost              0.8705095"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAY1BMVEUAAAAJCQkQEBAVFRUc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\neTcAyIF5NwDIwf8DYnHRu8RY7UUAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- get_training_df_clean()\n",
    "\n",
    "learners <- list(learner_A, learner_B, learner_C, learner_D, learner_E, learner_F, learner_G, learner_H, learner_I, learner_J)\n",
    "\n",
    "result <- cv_compare_learner(learners, df)\n",
    "\n",
    "df_test  <- get_test_df_clean()\n",
    "model_result_test <-  calculate_test_auc(learners, df, df_test)\n",
    "\n",
    "\n",
    "\n",
    "plot_best_learners(result, model_result_test)\n",
    "\n",
    "result %>% \n",
    "  group_by(model) %>%\n",
    "  summarise(MeanAUC = mean(auc)) %>%\n",
    "  arrange(desc(MeanAUC))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>model</th><th scope=col>auc</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>lg full              </td><td>0.8701923            </td></tr>\n",
       "\t<tr><td>lg forwad selection  </td><td>0.8521635            </td></tr>\n",
       "\t<tr><td>glm 5 variables LASSO</td><td>0.8449519            </td></tr>\n",
       "\t<tr><td>glmnet               </td><td>0.8713942            </td></tr>\n",
       "\t<tr><td>rpart                </td><td>0.8112981            </td></tr>\n",
       "\t<tr><td>bagging              </td><td>0.8659856            </td></tr>\n",
       "\t<tr><td>randomforest         </td><td>0.8407452            </td></tr>\n",
       "\t<tr><td>adaboost             </td><td>0.8485577            </td></tr>\n",
       "\t<tr><td>gbm                  </td><td>0.8701923            </td></tr>\n",
       "\t<tr><td>xgboost              </td><td>0.8653846            </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " model & auc\\\\\n",
       "\\hline\n",
       "\t lg full               & 0.8701923            \\\\\n",
       "\t lg forwad selection   & 0.8521635            \\\\\n",
       "\t glm 5 variables LASSO & 0.8449519            \\\\\n",
       "\t glmnet                & 0.8713942            \\\\\n",
       "\t rpart                 & 0.8112981            \\\\\n",
       "\t bagging               & 0.8659856            \\\\\n",
       "\t randomforest          & 0.8407452            \\\\\n",
       "\t adaboost              & 0.8485577            \\\\\n",
       "\t gbm                   & 0.8701923            \\\\\n",
       "\t xgboost               & 0.8653846            \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| model | auc |\n",
       "|---|---|\n",
       "| lg full               | 0.8701923             |\n",
       "| lg forwad selection   | 0.8521635             |\n",
       "| glm 5 variables LASSO | 0.8449519             |\n",
       "| glmnet                | 0.8713942             |\n",
       "| rpart                 | 0.8112981             |\n",
       "| bagging               | 0.8659856             |\n",
       "| randomforest          | 0.8407452             |\n",
       "| adaboost              | 0.8485577             |\n",
       "| gbm                   | 0.8701923             |\n",
       "| xgboost               | 0.8653846             |\n",
       "\n"
      ],
      "text/plain": [
       "   model                 auc      \n",
       "1  lg full               0.8701923\n",
       "2  lg forwad selection   0.8521635\n",
       "3  glm 5 variables LASSO 0.8449519\n",
       "4  glmnet                0.8713942\n",
       "5  rpart                 0.8112981\n",
       "6  bagging               0.8659856\n",
       "7  randomforest          0.8407452\n",
       "8  adaboost              0.8485577\n",
       "9  gbm                   0.8701923\n",
       "10 xgboost               0.8653846"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_result_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
