{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Models\n",
    "\n",
    "Define models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tidyverse' was built under R version 3.6.1\"Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n",
      "-- Attaching packages --------------------------------------- tidyverse 1.2.1 --\n",
      "v ggplot2 3.1.1       v purrr   0.3.2  \n",
      "v tibble  2.1.1       v dplyr   0.8.0.1\n",
      "v tidyr   0.8.3       v stringr 1.4.0  \n",
      "v readr   1.3.1       v forcats 0.4.0  \n",
      "-- Conflicts ------------------------------------------ tidyverse_conflicts() --\n",
      "x dplyr::filter() masks stats::filter()\n",
      "x dplyr::lag()    masks stats::lag()\n",
      "Warning message:\n",
      "\"package 'caret' was built under R version 3.6.1\"Loading required package: lattice\n",
      "\n",
      "Attaching package: 'caret'\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    lift\n",
      "\n",
      "Warning message:\n",
      "\"package 'MLmetrics' was built under R version 3.6.1\"\n",
      "Attaching package: 'MLmetrics'\n",
      "\n",
      "The following objects are masked from 'package:caret':\n",
      "\n",
      "    MAE, RMSE\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    Recall\n",
      "\n",
      "\n",
      "Attaching package: 'magrittr'\n",
      "\n",
      "The following object is masked from 'package:purrr':\n",
      "\n",
      "    set_names\n",
      "\n",
      "The following object is masked from 'package:tidyr':\n",
      "\n",
      "    extract\n",
      "\n",
      "Warning message:\n",
      "\"package 'glmnet' was built under R version 3.6.1\"Loading required package: Matrix\n",
      "\n",
      "Attaching package: 'Matrix'\n",
      "\n",
      "The following object is masked from 'package:tidyr':\n",
      "\n",
      "    expand\n",
      "\n",
      "Loaded glmnet 3.0\n",
      "\n",
      "Warning message:\n",
      "\"package 'rpart' was built under R version 3.6.1\"Warning message:\n",
      "\"package 'ipred' was built under R version 3.6.1\"Warning message:\n",
      "\"package 'randomForest' was built under R version 3.6.1\"randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: 'randomForest'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    margin\n",
      "\n",
      "Warning message:\n",
      "\"package 'fastAdaboost' was built under R version 3.6.1\"Warning message:\n",
      "\"package 'gbm' was built under R version 3.6.2\"Loaded gbm 2.1.5\n",
      "Warning message:\n",
      "\"package 'xgboost' was built under R version 3.6.2\"\n",
      "Attaching package: 'xgboost'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    slice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source(\"helpers.r\")\n",
    "library(magrittr)\n",
    "library(glmnet)\n",
    "library(rpart)\n",
    "library(ipred)\n",
    "library(randomForest)\n",
    "library(fastAdaboost)\n",
    "library(gbm)\n",
    "library(xgboost)\n",
    "\n",
    "learner_A <- function(training, test) {\n",
    "  name <- \"lg full\"\n",
    "  \n",
    "  fit <- glm(target ~ ., data=training, family =binomial(link = \"logit\"))\n",
    "  y_probabilities <- predict(fit, test,  type=\"response\")\n",
    "  y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "  \n",
    "  auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "  return(list(name = name, auc = auc))\n",
    "}\n",
    "\n",
    "\n",
    "learner_B <- function(training, test) {\n",
    "  name <- \"lg forwad selection\"\n",
    "  \n",
    "  fit <- glm(target ~ thal + ca + cp + slope + oldpeak + sex + trestbps, data=training, family =binomial(link = \"logit\"))\n",
    "  y_probabilities <- predict(fit, test,  type=\"response\")\n",
    "  y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "  \n",
    "  auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "  return(list(name = name, auc = auc))\n",
    "}\n",
    "\n",
    "learner_C <- function(training, test) {   \n",
    "  name <- \"glm 5 variables LASSO\"\n",
    "    \n",
    "  fit <- glm(target ~ thalach + oldpeak + ca + cp + thal, data=training, family = binomial(link = \"logit\"))\n",
    "  y_probabilities <- predict(fit, test,  type=\"response\")\n",
    "  y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "    \n",
    "  auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "  return(list(name = name, auc = auc))\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "learner_D <- function(training, test) {   \n",
    "    name <- \"glmnet\"\n",
    "    \n",
    "    model <- model.matrix(target ~ ., training)[,-1]\n",
    "    y <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "    fit <- glmnet(model, y, alpha = 0, family = \"binomial\", lambda = 0.5, standardize = TRUE)\n",
    "\n",
    "    x_test  <- model.matrix(target ~ ., test)[,-1]\n",
    "    y_probabilities <- predict(fit, x_test,  type=\"response\")\n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "}\n",
    "\n",
    "learner_E  <- function(training, test){\n",
    "    \n",
    "        name <- \"rpart\"\n",
    "    \n",
    "    model <- model.matrix(target ~ ., training)[,-1]\n",
    "    y <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "   \n",
    "        \n",
    "    fit <- rpart(target ~., data=df, method = \"class\",\n",
    "                 control = rpart.control(maxdepth = 5, minbucket = 10, minsplit = 10), cp = 0.1)\n",
    "\n",
    "    y_probabilities <- predict(fit, test)[,2]\n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "\n",
    "}\n",
    "\n",
    "learner_F <- function(training, test){\n",
    "    \n",
    "        name <- \"bagging\"\n",
    "    \n",
    "    model <- model.matrix(target ~ ., training)[,-1]\n",
    "    y <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "   \n",
    "        \n",
    "  fit <- bagging(target ~ ., training,\n",
    "                 nbagg = 100,\n",
    "                 coob = FALSE,\n",
    "                 control = rpart.control(maxdepth = 20, minbucket = 7,\n",
    "                                         minsplit = 10), cp = 0.1)\n",
    "  \n",
    "  y_probabilities <- predict(fit, test, type = \"prob\")[,2]\n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "learner_G <- function(training, test){\n",
    "    \n",
    "        name <- \"randomforest\"\n",
    "    \n",
    "    model <- model.matrix(target ~ ., training)[,-1]\n",
    "    y <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "   \n",
    "        \n",
    "     fit <- randomForest(target ~ ., training,  ntree = 100, mtry = 2,\n",
    "                        nodesize = 10, maxnodes = 4)\n",
    "    # using ratio of poisitive labels as probability\n",
    "    y_probabilities <- predict(fit, test, type = \"vote\")[,2]\n",
    "    \n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "\n",
    "}\n",
    "\n",
    "learner_H <- function(training, test){\n",
    "    \n",
    "        name <- \"adaboost\"\n",
    "    \n",
    "    model <- model.matrix(target ~ ., training)[,-1]\n",
    "    y <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "   \n",
    "    training <- as.data.frame(training) \n",
    "   fit <- adaboost(target ~ ., training, nIter = 100)\n",
    "    y_probabilities <- predict(fit, test)$prob[,2]\n",
    "    \n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "\n",
    "}\n",
    "\n",
    "learner_I <- function(training, test){\n",
    "    \n",
    "    name <- \"gbm\"\n",
    "\n",
    "    y <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    training$target <- ifelse(training$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    fit <- gbm(target ~ ., data = training, distribution = \"bernoulli\",\n",
    "         n.trees = 10, interaction.depth = 10,\n",
    "         n.minobsinnode = 5)\n",
    "\n",
    "\n",
    "\n",
    "    y_probabilities <- predict(fit, test, type = \"response\", n.trees = 10)\n",
    "   \n",
    "    \n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learner_J <- function(training, test) {\n",
    "    name <- \"xgboost\"\n",
    "\n",
    "    df_matrix <- sparse.model.matrix(target ~ .-1, data = training)\n",
    "    dtrain <- xgb.DMatrix(df_matrix, label = ifelse(training$target == \"no_disease\", 0, 1))\n",
    "\n",
    "    param <- list(max_depth = 2, eta = 0.1, verbose = 0, nthread = 2,\n",
    "          objective = \"binary:logistic\")\n",
    "\n",
    "    fit <- xgb.train(param, dtrain, nrounds = 50)\n",
    "\n",
    "    df_matrix <- sparse.model.matrix(target ~ .-1, data = test)\n",
    "    dtest <- xgb.DMatrix(df_matrix, label = ifelse(test$target == \"no_disease\", 0, 1))\n",
    "    \n",
    "    y_probabilities <- predict(fit, dtest)\n",
    "    y_true <- ifelse(test$target == \"no_disease\", 0, 1)\n",
    "\n",
    "    auc <- AUC(y_true = y_true, y_pred = y_probabilities)\n",
    "    return(list(name = name, auc = auc))\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>model</th><th scope=col>MeanAUC</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>lg forwad selection  </td><td>0.9227572            </td></tr>\n",
       "\t<tr><td>glmnet               </td><td>0.9196304            </td></tr>\n",
       "\t<tr><td>randomforest         </td><td>0.9129620            </td></tr>\n",
       "\t<tr><td>bagging              </td><td>0.9100699            </td></tr>\n",
       "\t<tr><td>glm 5 variables LASSO</td><td>0.9054346            </td></tr>\n",
       "\t<tr><td>lg full              </td><td>0.9035265            </td></tr>\n",
       "\t<tr><td>gbm                  </td><td>0.9029670            </td></tr>\n",
       "\t<tr><td>rpart                </td><td>0.8997053            </td></tr>\n",
       "\t<tr><td>xgboost              </td><td>0.8990210            </td></tr>\n",
       "\t<tr><td>adaboost             </td><td>0.8705095            </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " model & MeanAUC\\\\\n",
       "\\hline\n",
       "\t lg forwad selection   & 0.9227572            \\\\\n",
       "\t glmnet                & 0.9196304            \\\\\n",
       "\t randomforest          & 0.9129620            \\\\\n",
       "\t bagging               & 0.9100699            \\\\\n",
       "\t glm 5 variables LASSO & 0.9054346            \\\\\n",
       "\t lg full               & 0.9035265            \\\\\n",
       "\t gbm                   & 0.9029670            \\\\\n",
       "\t rpart                 & 0.8997053            \\\\\n",
       "\t xgboost               & 0.8990210            \\\\\n",
       "\t adaboost              & 0.8705095            \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| model | MeanAUC |\n",
       "|---|---|\n",
       "| lg forwad selection   | 0.9227572             |\n",
       "| glmnet                | 0.9196304             |\n",
       "| randomforest          | 0.9129620             |\n",
       "| bagging               | 0.9100699             |\n",
       "| glm 5 variables LASSO | 0.9054346             |\n",
       "| lg full               | 0.9035265             |\n",
       "| gbm                   | 0.9029670             |\n",
       "| rpart                 | 0.8997053             |\n",
       "| xgboost               | 0.8990210             |\n",
       "| adaboost              | 0.8705095             |\n",
       "\n"
      ],
      "text/plain": [
       "   model                 MeanAUC  \n",
       "1  lg forwad selection   0.9227572\n",
       "2  glmnet                0.9196304\n",
       "3  randomforest          0.9129620\n",
       "4  bagging               0.9100699\n",
       "5  glm 5 variables LASSO 0.9054346\n",
       "6  lg full               0.9035265\n",
       "7  gbm                   0.9029670\n",
       "8  rpart                 0.8997053\n",
       "9  xgboost               0.8990210\n",
       "10 adaboost              0.8705095"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAYFBMVEUAAAAJCQkMDAwQEBAV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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- get_training_df_clean()\n",
    "\n",
    "learners <- list(learner_A, learner_B, learner_C, learner_D, learner_E, learner_F, learner_G, learner_H, learner_I, learner_J)\n",
    "\n",
    "result <- cv_compare_learner(learners, df)\n",
    "\n",
    "plot_best_learners(result)\n",
    "\n",
    "result %>% \n",
    "  group_by(model) %>%\n",
    "  summarise(MeanAUC = mean(auc)) %>%\n",
    "  arrange(desc(MeanAUC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
